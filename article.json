[
  {
    "title": "CriteoPrivateAd: A Real-World Bidding Dataset to Design Private Advertising Systems",
    "url": "http://arxiv.org/abs/2502.12103v1",
    "authors": [
      "Mehdi Sebbar",
      "Corentin Odic",
      "Mathieu L\u00e9chine",
      "Alo\u00efs Bissuel",
      "Nicolas Chrysanthos",
      "Anthony D'Amato",
      "Alexandre Gilotte",
      "Fabian H\u00f6ring",
      "Sarah Nogueira",
      "Maxime Vono"
    ],
    "published": "2025-02-17T18:24:48+00:00",
    "summary": "In the past years, many proposals have emerged in order to address online advertising use-cases without access to third-party cookies. All these propo..."
  },
  {
    "title": "FedEAT: A Robustness Optimization Framework for Federated LLMs",
    "url": "http://arxiv.org/abs/2502.11863v1",
    "authors": [
      "Yahao Pang",
      "Xingyuan Wu",
      "Xiaojin Zhang",
      "Wei Chen",
      "Hai Jin"
    ],
    "published": "2025-02-17T14:55:46+00:00",
    "summary": "Significant advancements have been made by Large Language Models (LLMs) in the domains of natural language understanding and automated content creatio..."
  },
  {
    "title": "Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives",
    "url": "http://arxiv.org/abs/2502.11858v1",
    "authors": [
      "Zeliang Zhang",
      "Susan Liang",
      "Daiki Shimada",
      "Chenliang Xu"
    ],
    "published": "2025-02-17T14:50:34+00:00",
    "summary": "While audio-visual learning equips models with a richer understanding of the real world by leveraging multiple sensory modalities, this integration al..."
  },
  {
    "title": "BackdoorDM: A Comprehensive Benchmark for Backdoor Learning in Diffusion Model",
    "url": "http://arxiv.org/abs/2502.11798v1",
    "authors": [
      "Weilin Lin",
      "Nanjun Zhou",
      "Yanyun Wang",
      "Jianze Li",
      "Hui Xiong",
      "Li Liu"
    ],
    "published": "2025-02-17T13:39:05+00:00",
    "summary": "Backdoor learning is a critical research topic for understanding the vulnerabilities of deep neural networks. While it has been extensively studied in..."
  },
  {
    "title": "Lightweight Deepfake Detection Based on Multi-Feature Fusion",
    "url": "http://arxiv.org/abs/2502.11763v1",
    "authors": [
      "Siddiqui Muhammad Yasir",
      "Hyun Kim"
    ],
    "published": "2025-02-17T12:55:41+00:00",
    "summary": "Deepfake technology utilizes deep learning based face manipulation techniques to seamlessly replace faces in videos creating highly realistic but arti..."
  },
  {
    "title": "Incomplete Modality Disentangled Representation for Ophthalmic Disease Grading and Diagnosis",
    "url": "http://arxiv.org/abs/2502.11724v1",
    "authors": [
      "Chengzhi Liu",
      "Zile Huang",
      "Zhe Chen",
      "Feilong Tang",
      "Yu Tian",
      "Zhongxing Xu",
      "Zihong Luo",
      "Yalin Zheng",
      "Yanda Meng"
    ],
    "published": "2025-02-17T12:10:35+00:00",
    "summary": "Ophthalmologists typically require multimodal data sources to improve diagnostic accuracy in clinical decisions. However, due to medical device shorta..."
  },
  {
    "title": "ReVeil: Unconstrained Concealed Backdoor Attack on Deep Neural Networks using Machine Unlearning",
    "url": "http://arxiv.org/abs/2502.11687v1",
    "authors": [
      "Manaar Alam",
      "Hithem Lamri",
      "Michail Maniatakos"
    ],
    "published": "2025-02-17T11:25:28+00:00",
    "summary": "Backdoor attacks embed hidden functionalities in deep neural networks (DNN), triggering malicious behavior with specific inputs. Advanced defenses mon..."
  },
  {
    "title": "Double Momentum and Error Feedback for Clipping with Fast Rates and Differential Privacy",
    "url": "http://arxiv.org/abs/2502.11682v1",
    "authors": [
      "Rustem Islamov",
      "Samuel Horvath",
      "Aurelien Lucchi",
      "Peter Richtarik",
      "Eduard Gorbunov"
    ],
    "published": "2025-02-17T11:16:21+00:00",
    "summary": "Strong Differential Privacy (DP) and Optimization guarantees are two desirable properties for a method in Federated Learning (FL). However, existing a..."
  },
  {
    "title": "\"I'm not for sale\" -- Perceptions and limited awareness of privacy risks by digital natives about location data",
    "url": "http://arxiv.org/abs/2502.11658v1",
    "authors": [
      "Antoine Boutet",
      "Victor Morel"
    ],
    "published": "2025-02-17T10:49:23+00:00",
    "summary": "Although mobile devices benefit users in their daily lives in numerous ways, they also raise several privacy concerns. For instance, they can reveal s..."
  },
  {
    "title": "DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing",
    "url": "http://arxiv.org/abs/2502.11647v1",
    "authors": [
      "Yi Wang",
      "Fenghua Weng",
      "Sibei Yang",
      "Zhan Qin",
      "Minlie Huang",
      "Wenjie Wang"
    ],
    "published": "2025-02-17T10:39:21+00:00",
    "summary": "Large Language Models (LLMs) are widely applied in decision making, but their deployment is threatened by jailbreak attacks, where adversarial users m..."
  },
  {
    "title": "Membership Inference Attacks for Face Images Against Fine-Tuned Latent Diffusion Models",
    "url": "http://arxiv.org/abs/2502.11619v1",
    "authors": [
      "Lauritz Christian Holme",
      "Anton Mosquera Storgaard",
      "Siavash Arjomand Bigdeli"
    ],
    "published": "2025-02-17T10:01:24+00:00",
    "summary": "The rise of generative image models leads to privacy concerns when it comes to the huge datasets used to train such models. This paper investigates th..."
  },
  {
    "title": "User-Centric Data Management in Decentralized Internet of Behaviors System",
    "url": "http://arxiv.org/abs/2502.11616v1",
    "authors": [
      "Shiqi Zhang",
      "Dapeng Wu",
      "Honggang Wang",
      "Ruyan Wang"
    ],
    "published": "2025-02-17T09:59:25+00:00",
    "summary": "The Internet of Behaviors (IoB) is an emerging concept that utilizes devices to collect human behavior and provide intelligent services. Although some..."
  },
  {
    "title": "InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning",
    "url": "http://arxiv.org/abs/2502.11573v1",
    "authors": [
      "Congkai Xie",
      "Shuo Cai",
      "Wenjun Wang",
      "Pengxiang Li",
      "Zhijie Sang",
      "Kejing Yang",
      "Yiming Zhang",
      "Zhen Li",
      "Guanghao Zhu",
      "Zeyu Liu",
      "Yang Yu",
      "Yuhang Liu",
      "Su Lu",
      "Baoyi He",
      "Qi Zhou",
      "Xiaotian Han",
      "Jianbo Yuan",
      "Shengyu Zhang",
      "Fei Wu",
      "Hongxia Yang"
    ],
    "published": "2025-02-17T09:07:32+00:00",
    "summary": "Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have made significant advancements in reasoning capabilities. However, they ..."
  },
  {
    "title": "Trinity: A Scalable and Forward-Secure DSSE for Spatio-Temporal Range Query",
    "url": "http://arxiv.org/abs/2502.11550v1",
    "authors": [
      "Zhijun Li",
      "Kuizhi Liu",
      "Minghui Xu",
      "Xiangyu Wang",
      "Yinbin Miao",
      "Jianfeng Ma",
      "Xiuzhen Cheng"
    ],
    "published": "2025-02-17T08:30:42+00:00",
    "summary": "Cloud-based outsourced Location-based services have profound impacts on various aspects of people's lives but bring security concerns. Existing spatio..."
  },
  {
    "title": "Be Cautious When Merging Unfamiliar LLMs: A Phishing Model Capable of Stealing Privacy",
    "url": "http://arxiv.org/abs/2502.11533v1",
    "authors": [
      "Zhenyuan Guo",
      "Yi Shi",
      "Wenlong Meng",
      "Chen Gong",
      "Chengkun Wei",
      "Wenzhi Chen"
    ],
    "published": "2025-02-17T08:04:52+00:00",
    "summary": "Model merging is a widespread technology in large language models (LLMs) that integrates multiple task-specific LLMs into a unified one, enabling the ..."
  },
  {
    "title": "Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training",
    "url": "http://arxiv.org/abs/2502.11455v1",
    "authors": [
      "Fenghua Weng",
      "Jian Lou",
      "Jun Feng",
      "Minlie Huang",
      "Wenjie Wang"
    ],
    "published": "2025-02-17T05:28:47+00:00",
    "summary": "Safety alignment is critical in pre-training large language models (LLMs) to generate responses aligned with human values and refuse harmful queries. ..."
  },
  {
    "title": "From Personas to Talks: Revisiting the Impact of Personas on LLM-Synthesized Emotional Support Conversations",
    "url": "http://arxiv.org/abs/2502.11451v1",
    "authors": [
      "Shenghan Wu",
      "Yang Deng",
      "Yimo Zhu",
      "Wynne Hsu",
      "Mong Li Lee"
    ],
    "published": "2025-02-17T05:24:30+00:00",
    "summary": "The rapid advancement of Large Language Models (LLMs) has revolutionized the generation of emotional support conversations (ESC), offering scalable so..."
  },
  {
    "title": "Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning",
    "url": "http://arxiv.org/abs/2502.11441v1",
    "authors": [
      "Hwan Chang",
      "Hwanhee Lee"
    ],
    "published": "2025-02-17T04:55:02+00:00",
    "summary": "Large language models (LLMs) risk retaining unauthorized or sensitive information from their training data, which raises privacy concerns. LLM unlearn..."
  },
  {
    "title": "\"An Image of Ourselves in Our Minds\": How College-educated Online Dating Users Construct Profiles for Effective Self Presentation",
    "url": "http://arxiv.org/abs/2502.11430v1",
    "authors": [
      "Fan Zhang",
      "Yun Chen",
      "Xiaoke Zeng",
      "Tianqi Wang",
      "Long Ling",
      "RAY LC"
    ],
    "published": "2025-02-17T04:39:47+00:00",
    "summary": "Online dating is frequently used by individuals looking for potential relationships and intimate connections. Central to dating apps is the creation a..."
  },
  {
    "title": "Detecting and Filtering Unsafe Training Data via Data Attribution",
    "url": "http://arxiv.org/abs/2502.11411v1",
    "authors": [
      "Yijun Pan",
      "Taiwei Shi",
      "Jieyu Zhao",
      "Jiaqi W. Ma"
    ],
    "published": "2025-02-17T03:50:58+00:00",
    "summary": "Large language models (LLMs) are vulnerable to unsafe training data that even small amounts of unsafe data can lead to harmful model behaviors. Detect..."
  },
  {
    "title": "CCJA: Context-Coherent Jailbreak Attack for Aligned Large Language Models",
    "url": "http://arxiv.org/abs/2502.11379v1",
    "authors": [
      "Guanghao Zhou",
      "Panjia Qiu",
      "Mingyuan Fan",
      "Cen Chen",
      "Mingyuan Chu",
      "Xin Zhang",
      "Jun Zhou"
    ],
    "published": "2025-02-17T02:49:26+00:00",
    "summary": "Despite explicit alignment efforts for large language models (LLMs), they can still be exploited to trigger unintended behaviors, a phenomenon known a..."
  },
  {
    "title": "VLDBench: Vision Language Models Disinformation Detection Benchmark",
    "url": "http://arxiv.org/abs/2502.11361v1",
    "authors": [
      "Shaina Raza",
      "Ashmal Vayani",
      "Aditya Jain",
      "Aravind Narayanan",
      "Vahid Reza Khazaie",
      "Syed Raza Bashir",
      "Elham Dolatabadi",
      "Gias Uddin",
      "Christos Emmanouilidis",
      "Rizwan Qureshi",
      "Mubarak Shah"
    ],
    "published": "2025-02-17T02:18:47+00:00",
    "summary": "The rapid rise of AI-generated content has made detecting disinformation increasingly challenging. In particular, multimodal disinformation, i.e., onl..."
  },
  {
    "title": "Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System",
    "url": "http://arxiv.org/abs/2502.11358v1",
    "authors": [
      "Ziyou Jiang",
      "Mingyang Li",
      "Guowei Yang",
      "Junjie Wang",
      "Yuekai Huang",
      "Zhiyuan Chang",
      "Qing Wang"
    ],
    "published": "2025-02-17T02:15:46+00:00",
    "summary": "Information theft attacks pose a significant risk to Large Language Model (LLM) tool-learning systems. Adversaries can inject malicious commands throu..."
  },
  {
    "title": "Evaluating the Performance of the DeepSeek Model in Confidential Computing Environment",
    "url": "http://arxiv.org/abs/2502.11347v1",
    "authors": [
      "Ben Dong",
      "Qian Wang"
    ],
    "published": "2025-02-17T01:55:38+00:00",
    "summary": "The increasing adoption of Large Language Models (LLMs) in cloud environments raises critical security concerns, particularly regarding model confiden..."
  },
  {
    "title": "Differentially private fine-tuned NF-Net to predict GI cancer type",
    "url": "http://arxiv.org/abs/2502.11329v1",
    "authors": [
      "Sai Venkatesh Chilukoti",
      "Imran Hossen Md",
      "Liqun Shan",
      "Vijay Srinivas Tida",
      "Xiali Hei"
    ],
    "published": "2025-02-17T01:04:47+00:00",
    "summary": "Based on global genomic status, the cancer tumor is classified as Microsatellite Instable (MSI) and Microsatellite Stable (MSS). Immunotherapy is used..."
  },
  {
    "title": "VLMs as GeoGuessr Masters: Exceptional Performance, Hidden Biases, and Privacy Risks",
    "url": "http://arxiv.org/abs/2502.11163v1",
    "authors": [
      "Jingyuan Huang",
      "Jen-tse Huang",
      "Ziyi Liu",
      "Xiaoyuan Liu",
      "Wenxuan Wang",
      "Jieyu Zhao"
    ],
    "published": "2025-02-16T15:28:34+00:00",
    "summary": "Visual-Language Models (VLMs) have shown remarkable performance across various tasks, particularly in recognizing geographic information from images. ..."
  },
  {
    "title": "G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems",
    "url": "http://arxiv.org/abs/2502.11127v1",
    "authors": [
      "Shilong Wang",
      "Guibin Zhang",
      "Miao Yu",
      "Guancheng Wan",
      "Fanci Meng",
      "Chongye Guo",
      "Kun Wang",
      "Yang Wang"
    ],
    "published": "2025-02-16T13:48:41+00:00",
    "summary": "Large Language Model (LLM)-based Multi-agent Systems (MAS) have demonstrated remarkable capabilities in various complex tasks, ranging from collaborat..."
  },
  {
    "title": "Ramp Up NTT in Record Time using GPU-Accelerated Algorithms and LLM-based Code Generation",
    "url": "http://arxiv.org/abs/2502.11110v1",
    "authors": [
      "Yu Cui",
      "Hang Fu",
      "Licheng Wang",
      "Haibin Zhang"
    ],
    "published": "2025-02-16T12:53:23+00:00",
    "summary": "Homomorphic encryption (HE) is a core building block in privacy-preserving machine learning (PPML), but HE is also widely known as its efficiency bott..."
  },
  {
    "title": "SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks",
    "url": "http://arxiv.org/abs/2502.11090v1",
    "authors": [
      "Hongye Cao",
      "Yanming Wang",
      "Sijia Jing",
      "Ziyue Peng",
      "Zhixin Bai",
      "Zhe Cao",
      "Meng Fang",
      "Fan Feng",
      "Boyan Wang",
      "Jiaheng Liu",
      "Tianpei Yang",
      "Jing Huo",
      "Yang Gao",
      "Fanyu Meng",
      "Xi Yang",
      "Chao Deng",
      "Junlan Feng"
    ],
    "published": "2025-02-16T12:08:08+00:00",
    "summary": "With the rapid advancement of Large Language Models (LLMs), the safety of LLMs has been a critical concern requiring precise assessment. Current bench..."
  },
  {
    "title": "Rewrite to Jailbreak: Discover Learnable and Transferable Implicit Harmfulness Instruction",
    "url": "http://arxiv.org/abs/2502.11084v1",
    "authors": [
      "Yuting Huang",
      "Chengyuan Liu",
      "Yifeng Feng",
      "Chao Wu",
      "Fei Wu",
      "Kun Kuang"
    ],
    "published": "2025-02-16T11:43:39+00:00",
    "summary": "As Large Language Models (LLMs) are widely applied in various domains, the safety of LLMs is increasingly attracting attention to avoid their powerful..."
  },
  {
    "title": "DreamDDP: Accelerating Data Parallel Distributed LLM Training with Layer-wise Scheduled Partial Synchronization",
    "url": "http://arxiv.org/abs/2502.11058v1",
    "authors": [
      "Zhenheng Tang",
      "Zichen Tang",
      "Junlin Huang",
      "Xinglin Pan",
      "Rudan Yan",
      "Yuxin Wang",
      "Amelie Chi Zhou",
      "Shaohuai Shi",
      "Xiaowen Chu",
      "Bo Li"
    ],
    "published": "2025-02-16T09:51:57+00:00",
    "summary": "The growth of large language models (LLMs) increases challenges of accelerating distributed training across multiple GPUs in different data centers. M..."
  },
  {
    "title": "Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on Large Language Models",
    "url": "http://arxiv.org/abs/2502.11054v1",
    "authors": [
      "Zonghao Ying",
      "Deyue Zhang",
      "Zonglei Jing",
      "Yisong Xiao",
      "Quanchen Zou",
      "Aishan Liu",
      "Siyuan Liang",
      "Xiangzheng Zhang",
      "Xianglong Liu",
      "Dacheng Tao"
    ],
    "published": "2025-02-16T09:27:44+00:00",
    "summary": "Multi-turn jailbreak attacks simulate real-world human interactions by engaging large language models (LLMs) in iterative dialogues, exposing critical..."
  },
  {
    "title": "HawkEye: Statically and Accurately Profiling the Communication Cost of Models in Multi-party Learning",
    "url": "http://arxiv.org/abs/2502.11029v1",
    "authors": [
      "Wenqiang Ruan",
      "Xin Lin",
      "Ruisheng Zhou",
      "Guopeng Lin",
      "Shui Yu",
      "Weili Han"
    ],
    "published": "2025-02-16T07:49:27+00:00",
    "summary": "Multi-party computation (MPC) based machine learning, referred to as multi-party learning (MPL), has become an important technology for utilizing data..."
  },
  {
    "title": "Computing Inconsistency Measures Under Differential Privacy",
    "url": "http://arxiv.org/abs/2502.11009v1",
    "authors": [
      "Shubhankar Mohapatra",
      "Amir Gilad",
      "Xi He",
      "Benny Kimelfeld"
    ],
    "published": "2025-02-16T06:23:11+00:00",
    "summary": "Assessing data quality is crucial to knowing whether and how to use the data for different purposes. Specifically, given a collection of integrity con..."
  },
  {
    "title": "Prompt Inject Detection with Generative Explanation as an Investigative Tool",
    "url": "http://arxiv.org/abs/2502.11006v1",
    "authors": [
      "Jonathan Pan",
      "Swee Liang Wong",
      "Yidi Yuan",
      "Xin Wei Chia"
    ],
    "published": "2025-02-16T06:16:00+00:00",
    "summary": "Large Language Models (LLMs) are vulnerable to adversarial prompt based injects. These injects could jailbreak or exploit vulnerabilities within these..."
  },
  {
    "title": "New Rates in Stochastic Decision-Theoretic Online Learning under Differential Privacy",
    "url": "http://arxiv.org/abs/2502.10997v1",
    "authors": [
      "Ruihan Wu",
      "Yu-Xiang Wang"
    ],
    "published": "2025-02-16T05:13:51+00:00",
    "summary": "Hu and Mehta (2024) posed an open problem: what is the optimal instance-dependent rate for the stochastic decision-theoretic online learning (with $K$..."
  },
  {
    "title": "FaceSwapGuard: Safeguarding Facial Privacy from DeepFake Threats through Identity Obfuscation",
    "url": "http://arxiv.org/abs/2502.10801v1",
    "authors": [
      "Li Wang",
      "Zheng Li",
      "Xuhong Zhang",
      "Shouling Ji",
      "Shanqing Guo"
    ],
    "published": "2025-02-15T13:45:19+00:00",
    "summary": "DeepFakes pose a significant threat to our society. One representative DeepFake application is face-swapping, which replaces the identity in a facial ..."
  },
  {
    "title": "Distraction is All You Need for Multimodal Large Language Model Jailbreaking",
    "url": "http://arxiv.org/abs/2502.10794v1",
    "authors": [
      "Zuopeng Yang",
      "Jiluan Fan",
      "Anli Yan",
      "Erdun Gao",
      "Xin Lin",
      "Tao Li",
      "Kanghua mo",
      "Changyu Dong"
    ],
    "published": "2025-02-15T13:25:12+00:00",
    "summary": "Multimodal Large Language Models (MLLMs) bridge the gap between visual and textual data, enabling a range of advanced applications. However, complex i..."
  },
  {
    "title": "ReReLRP - Remembering and Recognizing Tasks with LRP",
    "url": "http://arxiv.org/abs/2502.10789v1",
    "authors": [
      "Karolina Bogacka",
      "Maximilian H\u00f6fler",
      "Maria Ganzha",
      "Wojciech Samek",
      "Katarzyna Wasielewska-Michniewska"
    ],
    "published": "2025-02-15T13:03:59+00:00",
    "summary": "Deep neural networks have revolutionized numerous research fields and applications. Despite their widespread success, a fundamental limitation known a..."
  },
  {
    "title": "Analyzing Privacy Dynamics within Groups using Gamified Auctions",
    "url": "http://arxiv.org/abs/2502.10788v1",
    "authors": [
      "H\u00fcseyin Ayd\u0131n",
      "Onuralp Ulusoy",
      "Ilaria Liccardi",
      "P\u0131nar Yolum"
    ],
    "published": "2025-02-15T12:48:30+00:00",
    "summary": "Online shared content, such as group pictures, often contains information about multiple users. Developing technical solutions to manage the privacy o..."
  },
  {
    "title": "Assessing the Trustworthiness of Electronic Identity Management Systems: Framework and Insights from Inception to Deployment",
    "url": "http://arxiv.org/abs/2502.10771v1",
    "authors": [
      "Mirko Bottarelli",
      "Gregory Epiphaniou",
      "Shah Mahmood",
      "Mark Hooper",
      "Carsten Maple"
    ],
    "published": "2025-02-15T11:26:30+00:00",
    "summary": "The growing dependence on Electronic Identity Management Systems (EIDS) and recent advancements, such as non-human ID management, require a thorough e..."
  },
  {
    "title": "BASE-SQL: A powerful open source Text-To-SQL baseline approach",
    "url": "http://arxiv.org/abs/2502.10739v1",
    "authors": [
      "Lei Sheng",
      "Shuai-Shuai Xu",
      "Wei Xie"
    ],
    "published": "2025-02-15T09:23:37+00:00",
    "summary": "The conversion of natural language into SQL language for querying databases (Text-to-SQL) has broad application prospects and has attracted widespread..."
  },
  {
    "title": "Unpacking the Layers: Exploring Self-Disclosure Norms, Engagement Dynamics, and Privacy Implications",
    "url": "http://arxiv.org/abs/2502.10701v1",
    "authors": [
      "Ehsan-Ul Haq",
      "Shalini Jangra",
      "Suparna De",
      "Nishanth Sastry",
      "Gareth Tyson"
    ],
    "published": "2025-02-15T07:15:09+00:00",
    "summary": "This paper characterizes the self-disclosure behavior of Reddit users across 11 different types of self-disclosure. We find that at least half of the ..."
  },
  {
    "title": "Privacy Preservation through Practical Machine Unlearning",
    "url": "http://arxiv.org/abs/2502.10635v1",
    "authors": [
      "Robert Dilworth"
    ],
    "published": "2025-02-15T02:25:27+00:00",
    "summary": "Machine Learning models thrive on vast datasets, continuously adapting to provide accurate predictions and recommendations. However, in an era dominat..."
  },
  {
    "title": "Federated Learning-Driven Cybersecurity Framework for IoT Networks with Privacy-Preserving and Real-Time Threat Detection Capabilities",
    "url": "http://arxiv.org/abs/2502.10599v1",
    "authors": [
      "Milad Rahmati"
    ],
    "published": "2025-02-14T23:11:51+00:00",
    "summary": "The rapid expansion of the Internet of Things (IoT) ecosystem has transformed various sectors but has also introduced significant cybersecurity challe..."
  },
  {
    "title": "Small Loss Bounds for Online Learning Separated Function Classes: A Gaussian Process Perspective",
    "url": "http://arxiv.org/abs/2502.10292v1",
    "authors": [
      "Adam Block",
      "Abhishek Shetty"
    ],
    "published": "2025-02-14T16:52:50+00:00",
    "summary": "In order to develop practical and efficient algorithms while circumventing overly pessimistic computational lower bounds, recent work has been interes..."
  },
  {
    "title": "Adversarial Mixup Unlearning",
    "url": "http://arxiv.org/abs/2502.10288v1",
    "authors": [
      "Zhuoyi Peng",
      "Yixuan Tang",
      "Yi Yang"
    ],
    "published": "2025-02-14T16:50:33+00:00",
    "summary": "Machine unlearning is a critical area of research aimed at safeguarding data privacy by enabling the removal of sensitive information from machine lea..."
  },
  {
    "title": "A Hybrid Cross-Stage Coordination Pre-ranking Model for Online Recommendation Systems",
    "url": "http://arxiv.org/abs/2502.10284v1",
    "authors": [
      "Binglei Zhao",
      "Houying Qi",
      "Guang Xu",
      "Mian Ma",
      "Xiwei Zhao",
      "Feng Mei",
      "Sulong Xu",
      "Jinghe Hu"
    ],
    "published": "2025-02-14T16:42:54+00:00",
    "summary": "Large-scale recommendation systems often adopt cascading architecture consisting of retrieval, pre-ranking, ranking, and re-ranking stages. With stric..."
  },
  {
    "title": "Efficient Zero-Order Federated Finetuning of Language Models for Resource-Constrained Devices",
    "url": "http://arxiv.org/abs/2502.10239v1",
    "authors": [
      "Mohamed Aboelenien Ahmed",
      "Kilian Pfeiffer",
      "Ramin Khalili",
      "Heba Khdr",
      "J\u00f6rg Henkel"
    ],
    "published": "2025-02-14T15:49:02+00:00",
    "summary": "Federated fine-tuning offers a promising approach for tuning Large Language Models (LLMs) on edge devices while preserving data privacy. However, fine..."
  },
  {
    "title": "RIPOST: Two-Phase Private Decomposition for Multidimensional Data",
    "url": "http://arxiv.org/abs/2502.10207v1",
    "authors": [
      "Ala Eddine Laouir",
      "Abdessamad Imine"
    ],
    "published": "2025-02-14T15:01:12+00:00",
    "summary": "Differential privacy (DP) is considered as the gold standard for data privacy. While the problem of answering simple queries and functions under DP gu..."
  }
]